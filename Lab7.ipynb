{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from os import path\n",
    "from os import listdir\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log2, e\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_mnist = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "test_mnist = torchvision.datasets.MNIST('./', download=True, train=False)\n",
    "X_train = train_mnist.train_data\n",
    "Y_train = train_mnist.train_labels\n",
    "X_test = test_mnist.train_data\n",
    "Y_test = test_mnist.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, :, :])\n",
    "plt.show()\n",
    "Y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.unsqueeze(1).float()\n",
    "X_test = X_test.unsqueeze(1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(torch.nn.Module):\n",
    "    def forward(self, X):\n",
    "        return X.view(X.size(0), X.size(1) * X.size(2) * X.size(3))\n",
    "    \n",
    "model1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    View(),\n",
    "\n",
    "    torch.nn.Linear(400, 120),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(120, 84),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|â–Š                                                                                 | 1/100 [00:29<48:11, 29.21s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 180.00 MiB (GPU 0; 2.00 GiB total capacity; 955.45 MiB already allocated; 82.88 MiB free; 1.03 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8a8a649f3078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mloss_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1136\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 180.00 MiB (GPU 0; 2.00 GiB total capacity; 955.45 MiB already allocated; 82.88 MiB free; 1.03 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "batch = 100\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "accuracy_array = []\n",
    "loss_array = []\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for i in range(600):\n",
    "        indexes = np.random.randint(0, 60000, batch)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model1(X_train[indexes])\n",
    "        loss_value = loss(y_pred, Y_train[indexes])\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "    y_pred = model1(X_test)\n",
    "    y_pred = y_pred.cpu()\n",
    "    loss_array.append(loss(y_pred, Y_test))\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_pred_real = [0] * len(y_pred)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred_real[i] = y_pred[i].argmax()\n",
    "    accuracy_array.append(accuracy_score(Y_test.detach().numpy(), y_pred_real))\n",
    "    print(accuracy_score(Y_test.detach().numpy(), y_pred_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
